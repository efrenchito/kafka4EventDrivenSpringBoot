üì¢ Apache Kafka for Event-Driven Spring Boot Microservices  by Sergety Kargopolov
=======================================================================================================================================

üìù S01 : Apache Kafka Introduction 
üìù S02 : Apache Kafka Broker
üìù S03 : Kafka Topics - CLI
üìù S04 : Kafka Producers - CLI
üìù S05 : Kafka Consumers - CLI
üìù S06 : Kafka Producer - Spring Boot Microservice
üìù S07 : Kafka Producer - Acknowledgment & Retries
üìù S08 : Kafka Producer - Idempotency
üìù S09 : Kafka Consumer - Spring Boot Microservice
üìù S10 : Kafka Consumer - Handling Deserialization Errors
üìù S11 : Kafka Consumer - Kafka Consumer Dead Letter Topic
üìù S12 : Kafka Consumer - Exceptions and Retries
üìù S13 : Kafka Consumer - Multiple Consumers in a Consumer Group
üìù S14 : Kafka Consumer Idempotency
üìù S15 : Apache Kafka Transactions
üìù S16 : Apache Kafka and Database Transactions
üìù S17 : Integration Testing - Kafka Producer
üìù S18 : Integration Testing - Kafka Consumer
üìù S19 : Saga Design Pattern I  - with Apache Kafka
üìù S20 : Saga Design Pattern II - Compensating Transactions
üìù S21 : Appendix A: Run Apache Kafka in a Docker Container
üìù S22 : Appendix B: Install Apache Kafka on Windows





üì£ Section 09 - Kafka Consumer - Spring Boot Microservice
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Create a Spring Boot Application with Spring Web [WEB] & Spring for Apache Kafka [MESSAGING] as Dependencies
[‚úèÔ∏è#~/...application.yml]
spring:
  kafka:
    consumer:
      group-id: product-created-events
      bootstrap-servers: localhost:9092
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring.json.trusted.packages: "*"


To work with a Kafka Consumer within Spring Boot...
We'll use a @Component class 
 -> @KafkaListener is a class/method level annotation that allow us to define the Topics we'll be listening to
 -> @KafkaHandler allow us to specify the format type a method will handle
    .. This will define the link between a 
=======================================================================================================================================

üöÄ Kafka Consumer - Introduction
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
=======================================================================================================================================
In this lesson we'll create Kafka Consumers as another Microservice
üßêüïµÔ∏èüîé When needed you can have multiple Kafka consumes running...
 -> This way each Kafka Consumers will receive their own copy of a Message


                                                                  ____        SMS
                                                                 /        Notification
                                                                /         MicroService
                                                               /           <Consumer> 
                                                              /
      Products         Publish                        Consume               Email 
    Microservice  ------------------>    Topic    <---------------       Notification
     <Producer>        (Message)                     (Message)           Microservice
                                                              \           <Consumer>
                                                               \
                                                                \            Push
                                                                 \____    Notification
                                                                          MicroService
                                                                           <Consumer> 


üß®‚ö†Ô∏èü§Ø As mentioned before...
So, a Kafka Topic defines the number of Partitions. 
Each message will be stored in its own partition. So, each Partition will store its own set of Messages.
ü§ì You must decide how many partitions to create for a Topic. (According to your business need)

           Kafka Topic (Product-created-event-topic)
Partition-0| 0 | 1 | 2 | 3 | 4 | 5 | n 
Partition-1| 0 | 1 | 2 |   |   |   | n
Partition-2| 0 | 1 | 2 | 3 | 4 |   | n

When you start a Kafka Consumer Microservice, it'll be pulling messages from Kafka Topic at a regular time interval. 
 -> This interval can be configured through configuration properties.

...

üßêüïµÔ∏èüîé Kafka Consumers will read data from Partition
When Kafka consumer reads messages from partitions, it reads them in parallel.
There is no order guarantee about which messages and which partitions will be read first
 -> However it does read messages in order within a single partition.

üß®‚ö†Ô∏èü§Ø Messages within a single partition are always read in order
 -> But there is no order guarantee between partitions.

üßêüïµÔ∏èüîé If you have a single application, then it will read messages from all three partitions.
But if you have three consumers running, then each consumer will be assigned to read messages from one partition only.
  -> If you need to scale up your application and you want to start more instances of the same consumer microservice,
     ..then this instances of Kafka consumer, they can be grouped together and work as a group.
  -> Each consumer reading messages from its own partition. This will help you process messages from Kafka topic faster.


üß®‚ö†Ô∏èü§Ø Once Kafka consumer reads message from Kafka topic, it does NOT delete messageS from the topic.
 -> The message remains in the topic until it is deleted from there automatically.
 -> By default, Kafka Topic is configured to keep messages for 168 hours (7 DAYS)
 => If needed, you can change this value using Configuration properties file.





~





üöÄ Creating a New Spring Boot Application
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
=======================================================================================================================================

‚öì https://start.spring.io

Language:  Java
Packaging: Jar
Version: 17

Project:  Maven
Group: com.learning.kafka
Artifact: EmailNotificationMicroservice
Name: Artifact: EmailNotificationMicroservice
Description: Email Notification Microservice
Package name: com.learning.kafka.emailnotification

Spring Boot
 Version: 3+

Dependencies: 
 o Spring Web [WEB]
 o Spring for Apache Kafka [MESSAGING]

    => Finish




~





üöÄ Kafka Consumer : Configuration Properties
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
üßêüïµÔ∏èüîé server.port=0  -> Assign a port randomly

[‚úèÔ∏è#~/...application.properties]
server.port=0
spring.kafka.consumer.group-id=product-created-events
spring.kafka.consumer.boostrap-servers=localhost:9092
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=*
=======================================================================================================================================

üßêüïµÔ∏èüîé port number set to zero will make my email notification microservice start up on a random port number.
üßêüïµÔ∏èüîé `bootstrap-servers` property, it is used to specify a list of bootstrap servers.
 -> A Bootstrap Server is used for Initial Connection to Kafka cluster.
 -> Notice this is very similar to the one we use for a producer
 => However here we're using üí•'consumer'üí•  instead of 'producer'
~
üß®‚ö†Ô∏èü§Ø One server is enough, but if you have more brokers in the cluster...
 -> Then it is better to provide at least two bootstrap servers here.

üßêüïµÔ∏èüîé Consumer Group in Kafka... 
 -> Is a group of Kafka Consumers Microservices that work together to consume messages from a topic.
 => All microservices that belong to the same group. They'll work together to process messages related to a Topic


üßêüïµÔ∏èüîé 'spring.json.trusted.packages' property specify one or more packages that are considered trusted for deserialization when processing JSON messages.
  -> If you know the application that publishes events is trustable
  => Then you can allow any package and use '*' asterix instead of a package name.
  ‚úÖ For security reasons it's adivisable to use Least-Privilege Principle specifying a particular package


[‚úèÔ∏è#~/...application.properties]
server.port=0
spring.kafka.consumer.group-id=product-created-events
spring.kafka.consumer.boostrap-servers=localhost:9092
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=*





~





üöÄ Kafka Consumer : @KafkaListener and @KafkaHandler annotations
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
=======================================================================================================================================
Let's create a new class that will be used to handle or consume 'Product Created Events'

[IntelliJ] > EmailNotificationMicroservice

[‚úèÔ∏è#~/...ProductCreatedEventHandler]
package com.learning.kafka.emailnotification.handler;

import org.springframework.stereotype.Component;
import org.springframework.kafka.annotation.KafkaListener;

@Component
@KafkaListener(topics = "product-created-event-topic")
public class ProductCreatedEventHandler {

    private final Logger LOGGER = LoggerFactory.getLogger(this.getClass());

    //@KafkaListener(topics = "product-created-event-topic")
    @KafkaHandler
    public void handle(ProductCreatedEvent productCreatedEvent) {
        LOGGER.info("Received a new Event: " + productCreatedEvent.getTitle());
    }

}
~
üßêüïµÔ∏èüîé @KafkaListener annotation can be used as {Class|Method}-level annotation
 -> It's used to mark a Class/Method as target for incoming messages from Kafka Topic
...
üß®‚ö†Ô∏èü§Ø @KafkaListener can be configured to listen from multiple topics
e.g. @KafkaListener(topics = {"topic1", "topic2"})
 -> A single Kafka Consumer can consume messages from multiple topics

üßêüïµÔ∏èüîé If the custom class is going to consume messages from multiple Topics 
 -> we can use @KafkaListener as Class-level annotation 
 => In this case methods should be annotated with @KafkaHandler
...
üß®‚ö†Ô∏èü§Ø To specify which particular event your method is listening to
 -> Be aware of declaring the Event type expected as argument within the method

~

üß®‚ö†Ô∏èü§Ø @KafkaHandler method wont be invoked by ourselves
This method will be called automatically as soon as Kafka Consumer receives a new message from Kafka Topic





~





üöÄ Kafka Consumer : Creating the "Core" Module
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
=======================================================================================================================================
Let's create a new Project...
This will be a centralized or shared project that both of my Microservices (Producer/Consumer) will use
 -> Later on we'll add this project as Maven dependency to both Microservices

‚öì https://start.spring.io

Language:  Java
Packaging: Jar
Version: 17

Project:  Maven
Group: com.learning.kafka
Artifact: Core
Name: Artifact: Core
Description: Shared Core Library
Package name: com.learning.kafka.core

Spring Boot
 Version: 3+

Dependencies:

  => Finish


üìù Remove NO needed elements from Project
---------------

[IntelliJ] > Core

[‚úèÔ∏è#~/...Core]
  ‚ùå src/main/java/.../CoreApplication.java
  ‚ùå src/test/java/.../CoreApplicationTest.java


[‚úèÔ∏è#~/...pom.xml]
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="...">
  <modelVersion>4.0.0</modelVersion>
  <parent> ...  </parent>
  <groupId>com.learning.kafka</groupId>  üí•
  <artifactId>core</artifactId>          üí•
  <version>0.0.1-SNAPSHOT</version>      üí•
  ...
  <dependencies>
    <!-- <dependency> -->
      <!-- <groupId>org.springframework.boot</groupId> -->
      <!-- <artifact>spring-boot-starter</artifactId> -->
    <!-- </dependency> -->
    <!-- <dependency> -->
      <!-- <groupId>org.springframework.boot</groupId> -->
      <!-- <artifact>spring-boot-starter-test</artifactId> -->
      <!-- <scope>test</scope> -->
    <!-- </dependency> -->
  </dependency>  
  <!-- <build> 
         <plugins>
           <plugin> ...-->
    ...
  ...
</project>


‚úèÔ∏è>>> Copy & Paste ProductCreatedEvent from 'ProductsMicroservice'  to  'Core'
‚úÖ src/main/java/.../ProductCreatedEvent.java
    ...


[terminal]
$ mvn clean install
~
This will add 'Core' dependency to your Maven HOME directory




~





üöÄ Kafka Consumer : Adding Core Project as Dependency to other Microservices
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
=======================================================================================================================================

Copy Core project coordinates form Core/pom.xml

[IntelliJ]  <Core>
[‚úèÔ∏è#~/...pom.xml]
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="...">
  <modelVersion>4.0.0</modelVersion>
  <parent> ...  </parent>
  <groupId>com.learning.kafka</groupId>  üí•
  <artifactId>core</artifactId>          üí•
  <version>0.0.1-SNAPSHOT</version>      üí•
  ...


[IntelliJ]  <ProductService>
[‚úèÔ∏è#~/...pom.xml]
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="...">
  <modelVersion>4.0.0</modelVersion>
  <parent> ...  </parent>
  ...
  <dependencies>
    <dependency>
      <groupId>com.learning.kafka</groupId>  ‚úÖ
      <artifactId>core</artifactId>          ‚úÖ
      <version>0.0.1-SNAPSHOT</version>      ‚úÖ
    </dependency>  


‚ùå Remove src/main/java/.../ProductCreatedEvent

‚úÖ Import ProductCreatedEvent to  üí•ProductServiceImplüí•
  ...
  ..
  .


~


[IntelliJ]  <EmailNotificationService>
[‚úèÔ∏è#~/...pom.xml]
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="...">
  <modelVersion>4.0.0</modelVersion>
  <parent> ...  </parent>
  ...
  <dependencies>
    <dependency>
      <groupId>com.learning.kafka</groupId>  ‚úÖ
      <artifactId>core</artifactId>          ‚úÖ
      <version>0.0.1-SNAPSHOT</version>      ‚úÖ
    </dependency>  


‚úÖ Import ProductCreatedEvent to  üí•'ProductCreatedEventHandler'üí•
  ...
  ..
  .





~





üöÄ Kafka Consumer : @KafkaListener + @KafkaHandler Trying how it works [Demo]
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
=======================================================================================================================================
Let's run my Kafka producer and Kafka Consumer microservices.
I will then publish event and we'll check if the consumer microservice was able to receive this event.
So let's it try now.


[terminal1]
$ ./bin/kafka-server-start.sh config/kraft/server-1.properties

[terminal2]
$ ./bin/kafka-server-start.sh config/kraft/server-2.properties

[termina3]
$ ./bin/kafka-server-start.sh config/kraft/server-3.properties


...


[IntelliJ]
ProductsMicroservice
  > ‚ñ∂Ô∏è ProductsMicroserviceApplication

...

[IntelliJ]
EmailNotificationMicroservice
  > ‚ñ∂Ô∏è EmailNotifiactionMicroserviceApplication


~


[POSTMAN]
[POST] http://localhost:{PORT}/products
Params | Authorization | Headers | ‚úÖBody | Pre-request Script | Tests | Settings
none | form-data | x-www-form-urlencoded | ‚úÖraw | binary | GraphQL | üí•JSON
~
{
    "title": "iPhone11",
    "price": 800,
    "quantity": 19
}
...
‚úÖBody | Cookies | Headers(5) | Test Results                 Status: 201 Created  Time: 236 ms   Size: 205 B
Pretty | Raw | Preview | Visualize | Text 
 {productId}


[IntelliJ]
EmailNotificationMicroservice
  > ‚ñ∂Ô∏è EmailNotifiactionMicroserviceApplication
~
product-created-events: partitions assigned: [product-created-events-topic-0, product-created-events-topic-1, product-created-events-topic-2] 
Received a new event: iPhone11
|





~





üöÄ Kafka Consumer : Spring Bean Configuration
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
=======================================================================================================================================
Let's configure Kafka Consumer in Java Code using Spring Bean

[IntelliJ]
<EmailNotificationMicroservice>
[‚úèÔ∏è#~/...application.properties]
spring.kafka.consumer.group-id=product-created-events
spring.kafka.consumer.bootstrap-servers=localhost:9092,localhost:9094
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=com.learning.kafka.product.service
~
üßêüïµÔ∏èüîé Notice in this case we're defining the properties bellow:
group-id | bootstrap-servers | key-deserializer | value-deserializer | json.trusted.packages
 -> Since we are dealing with a Consumer we're using  üí•key-deserializerüí• & üí•value-deserializerüí•
...
üß®‚ö†Ô∏èü§Ø The value expected here is marked as a Json (Therefore the value-deserializer is JsonDeserializer)
 -> Notice we can define the list of trusted packages this values can come from
 => We've selected the package defined at the Producer (ProductCreatedEvent)
üîé>>> 
<ProductsMicroservice>
[‚úèÔ∏è#~/...ProductCreatedEvent]
package com.learning.kafka.product.service;



<EmailNotificationMicroservice>
[‚úèÔ∏è#~/...KafkaConsumerConfiguration]
package com.learning.kafka.emailnotification;

import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.core.env.Environment;

import org.springframework.kafka.clients.consumer.ConsumerConfig;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;

import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.kafka.support.serializer.JsonDeserializer;

import java.util.Map;
import java.util.HashMap;

@Configuration
public class KafkaConsumerConfiguration {

    private Environment environment;

    public KafkaConsumerConfiguration(Environment environment) {
        this.environment = environment;
    }

    @Bean
    public ConsumerFactory<String, Object> consumerFactory() {
        Map<String, Object> config = new HashMap<>();
        config.put(ConsumerConfig.GROUP_ID_CONFIG, environment.getProperty("spring.kafka.consumer.group-id"));
        config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, environment.getProperty("spring.kafka.consumer.bootstrap-servers"));
        config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
        config.put(JsonDeserializer.TRUSTED_PACKAGES, environment.getProperty("spring.kafka.consumer.properties.spring.json.trusted.packages"));
        return new DefaultKafkaConsumerFactory<>(config);
    }

}
~
üßêüïµÔ∏èüîé We don't need to call consumerFactory() method ourselves...
 -> Spring Framework will invoke this method when our application starts up
...
üßêüïµÔ∏èüîé ConsumerFactory is a Spring Kafka Interface used to create instances of Kafka Consumer
 -> In this case we're returning a DefaultKafkaConsumerFactory which provides a default implementation of create consumer
    ..It takes a Map of Configuration Properties as input and returns an instance of Kafka Consumer

üß®‚ö†Ô∏èü§Ø So, instead of providing Consumer Configuration Properties via application.properties file 
 -> We'll now refer to them in a HashMap as Key value pairs via Environment Object
üìù 'org.springframework.core.env.Environment' it's used to represent the current Environment our application is running on
 -> We can use it to access configuration properties and other environment specific information
 => To access a property we use environment.getProperty("{PROPERTY-NAME}");





~





üöÄ Kafka Consumer : Kafka Listener Container Factory
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
=======================================================================================================================================
Kafka Consumer Object is a Client that can read messages from Kafka Cluster.

üßêüïµÔ∏èüîé The consumerFactory we created in the previous lesson...
-> Configures some settings for Kafka Consumer Objects, like for example:
  - Which service to connect to
  - How to convert messages into Java objects
üßêüïµÔ∏èüîé Notice this method was defined in a @Configuration class and annotated with @Bean 
 -> This means it can be used as a Bean from the ApplicationContext that need Kafka Consumer Objects

üß®‚ö†Ô∏èü§Ø In this lesson we'll create a Kafka Listener Container
 -> Kafka Listener Container will be responsible of receiving messages from Kafka Topic
    .. and invoking the handler method for the listener method in our Java code.


<EmailNotificationMicroservice>
[‚úèÔ∏è#~/...KafkaConsumerConfiguration]
package com.learning.kafka.emailnotification;

import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.core.env.Environment;

import org.springframework.kafka.clients.consumer.ConsumerConfig;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;

import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.kafka.support.serializer.JsonDeserializer;

import java.util.Map;
import java.util.HashMap;

@Configuration
public class KafkaConsumerConfiguration {

    private Environment environment;

    public KafkaConsumerConfiguration(Environment environment) {
        this.environment = environment;
    }

    @Bean
    public ConsumerFactory<String, Object> consumerFactory() {
        Map<String, Object> config = new HashMap<>();
        config.put(ConsumerConfig.GROUP_ID_CONFIG, environment.getProperty("spring.kafka.consumer.group-id"));
        config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, environment.getProperty("spring.kafka.consumer.bootstrap-servers"));
        config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
        config.put(JsonDeserializer.TRUSTED_PACKAGES, environment.getProperty("spring.kafka.consumer.properties.spring.json.trusted.packages"));
        return new DefaultKafkaConsumerFactory<>(config);
    }

    @Bean
    ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(ConsumerFactory<String, Object> ConsumerFactory) {
       ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
       factory.setConsumerFactory(consumerFactory);

       return factory;
    }

}
~
üìù Kafka Listener Container object is a component that interacts with Kafka Cluster to receive messages and invoke your listener methods
üß®‚ö†Ô∏èü§Ø This method creates a ConcurrentKafkaListenerContainerFactory a special object required to create Kafka Listener Objects
üßêüïµÔ∏èüîé Notice this ConcurrentKafkaListenerContainerFactory method, takes a ConsumerFactory as argument
 -> ConsumerFactory is used to tell 'ConcurrentKafkaListenerContainerFactory' how to create a Kafka Consumer Object
 => This 'ConsumerFactory' corresponds to the Bean created in the previous lesson
...





~





üöÄ Kafka Consumer : KafKa Consumer Bean Configurations [Demo]
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
=======================================================================================================================================

‚úèÔ∏è>>> Run ProductServiceApplication  üëáüëáüëá
[IntelliJ]
ProductsMicroservice
  > ‚ñ∂Ô∏è ProductsMicroserviceApplication

...

‚úèÔ∏è>>> Run EmailNotifiactionMicroserviceApplication  üëáüëáüëá
[IntelliJ]
EmailNotifiactionMicroservice
  > ‚ñ∂Ô∏è EmailNotifiactionMicroserviceApplication


...


‚úèÔ∏è>>> Send Kafka Message via POSTMAN >>>
-------------------------
[POSTMAN]
[POST] http://localhost:{PORT}/products
Params | Authorization | Headers | ‚úÖBody | Pre-request Script | Tests | Settings
none | form-data | x-www-form-urlencoded | ‚úÖraw | binary | GraphQL | üí•JSON
~
{
    "title": "iPhone11",
    "price": 800,
    "quantity": 19
}
...
‚úÖBody | Cookies | Headers(5) | Test Results                 Status: 201 Created  Time: 236 ms   Size: 205 B
Pretty | Raw | Preview | Visualize | Text 
 {productId}


...


[IntelliJ]
EmailNotifiactionMicroservice
  > ‚ñ∂Ô∏è EmailNotifiactionMicroserviceApplication
~
product-created-events: partitions assigned:  [product-created-events...
Received a new event: IPhone11





~





‚ùì Quiz: Apache Kafka Consumer - Quiz 6|6 questions
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
üìù What is the primary function of a Kafka Consumer?
üìù Can a single Kafka Consumer consume messages from more than one topic?
üìù What is the purpose of the @KafkaHandler annotation in a Kafka Consumer application?
üìù What distinguishes the @KafkaHandler annotation from the @KafkaListener annotation?
üìù What is the difference between a keydeserializer & valuedeserializer?
üìù What role does the spring.json.trusted.packages property plays?
=======================================================================================================================================

üìù Question 1:
What is the primary function of a Kafka consumer‚ùì
[ ] To produce and send messages to Kafka Topics
‚úÖ To read and process messages from Kafka Topics
[ ] To replicate messages across multiple Kafka Brokers
~
The primary function of a Kafka Consumer is to read and process messages from Kafka Topics
Consumers subscribe to one or more Kafka Topics and then process the stream of messages that are published to these topics


üìù Question 2:
Can a single Kafka consumer consume messages from more than one topic‚ùì
‚úÖ Yes, a consumer can be configured to consume messages from multiple topics simultaneously.
[ ] No, each consumer can only be linked to one topic at a time
~
A Kafka consumer can indeed be configured to consume messages from multiple topics.
This allows for greater flexibility and efficient utilization of consumers, especially when dealing with a variety of topics that require similar processing logic.


üìù Question 3:
What is the purpose of the @KafkaHandler annotation in a Kafka Consumer Application‚ùì
‚úÖ To define multiple methods in a listener class for different types of Kafka messages
[ ] To specify the topic that the Kafka Consumer should listen to
[ ] To increase the throughput of the Kafka Consumer by processing messages in parallel
~
The @KafkaHandler annotation is used within a Kafka listener class to define multiple methods for handling different types of messages.
Each method annotated with @KafkaHandler can be tailored to process a specific type of message.
This allows for a more organized and type-specific handling of messages within a single listener class, improving the clarity and maintainability of code


üìù Question 4:
What distinguishes the @KafkaHandler annotation from the @KafkaListener annotation in a Kafka Consumer Application‚ùì
[ ] @KafkaHandler is used to specify the Kafka topic the method should listen to,
    while @KafkaListener is used for handling specific message types
[ ] @KafkaHandler can be used at the class level, while @KafkaListener cannot.
‚úÖ @KafkaHandler is used to handle specific message types within a  @KafkaListener class,
   whereas @KafkaListener is used to define the methods that listen to messages from Kafka topics
~
@KafkaHandler is used within a class that has @KafkaListener to handle specific message types, 
allowing for differentiated processing based on message content. 
This annotation cannot be used to specify the Kafka topic nor can it be placed above the class name.
On the other hand, @KafkaListener is used to define methods (or classes) that specifically listen 
to messages from Kafka topics, and it can be used to specify the topic to listen to.


üìù Question 5:
What is the difference between the spring.kafka.consumer.keydeserializer 
and spring.kafka.consumer.value-deserializer configuration properties in a Kafka Consumer application‚ùì
[ ] key-deserializer configures the consumer's polling behavior, 
    while value-deserializer configures the consumer's session timeout.
[ ] key-deserializer and value-deserializer are both used for configuring the consumer's message fetch size
‚úÖ key-deserializer specifies the deserializer class for message keys, 
    while value-deserializer specifies the deserializer class for message values.
~
The spring.kafka.consumer.keydeserializer property is used to specify the deserializer class for the keys of Kafka messages
spring.kafka.consumer.value-deserializer is for specifying the deserializer class for the values of the messages.
Deserializers are important as they convert the byte stream received from Kafka into a format that can be understood
and processed by the consumer application


üìù Question 6:
In a Kafka Consumer application, what role does the spring.kafka.consumer.properties.spring.json.trusted.packages configuration play‚ùì
‚úÖ It determines the packages allowed for deserializing JSON messages, ensuring only objects from known sources are processed
[ ] It influences how JSON messages are mapped to Java objects, affecting data type conversions during deserialization
[ ] It controls the handling of JSON payload type information, impacting the deserialization of complex data types
~
spring.json.trusted.packages property specifies the packages that are considered safe for JSON message deserialization.
It's a security measure to prevent the application from deserializing objects from unknown or untrusted sources, thus mitigating potential security risks.