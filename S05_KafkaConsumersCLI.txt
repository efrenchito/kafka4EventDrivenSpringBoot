ðŸ“¢ Apache Kafka for Event-Driven Spring Boot Microservices  by Sergety Kargopolov
=======================================================================================================================================

ðŸ“ S01 : Apache Kafka Introduction 
ðŸ“ S02 : Apache Kafka Broker
ðŸ“ S03 : Kafka Topics - CLI
ðŸ“ S04 : Kafka Producers - CLI
ðŸ“ S05 : Kafka Consumers - CLI
ðŸ“ S06 : Kafka Producer - Spring Boot Microservice
ðŸ“ S07 : Kafka Producer - Acknowledgement & Retries
ðŸ“ S08 : Kafka Producer - Idempotency
ðŸ“ S09 : Kafka Consumer - Spring Boot Microservice
ðŸ“ S10 : Kafka Consumer - Handling Deserialization Errors
ðŸ“ S11 : Kafka Consumer - Exceptions and Retries
ðŸ“ S12 : Kafka Consumer - Multiple Consumers in a Consumer Group
ðŸ“ S13 : Kafka Consumer - Idempotency
ðŸ“ S14 : Apache Kafka and Database Transactions
ðŸ“ S15 : Apache Kafka Transactions
ðŸ“ S16 : Apache Kafka and Database Transactions
ðŸ“ S17 : Integration Testing - Kafka Producer
ðŸ“ S18 : Integration Testing - Kafka Consumer
ðŸ“ S19 : Saga Design Pattern I  - with Apache Kafka
ðŸ“ S20 : Saga Design Pattern II - Compensating Transactions
ðŸ“ S21 : Appendix A: Run Apache Kafka in a Docker Container
ðŸ“ S22 : Appendix B: Install Apache Kafka on Windows





ðŸ“£ Section 05 - Kafka Consumers - CLI
=======================================================================================================================================

ðŸš€ Introduction to Kafka Consumers - CLI
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
=======================================================================================================================================
Kafka Console Consumer Allow us to consume or read messages from a particular Kafka topic
The main use of Kafka console consumer is to fetch or display messages from Kafka topic to your terminal.

Notice when reading Kafka messages you can:
 o Read new messages only
 o Read all messages from the beginning 

...

[terminal]
$ cd {WORKSPACE}
$ cd kafka
$ ls
LICENSE  ðŸ’¥bin      libs    site-docs
NOTICE   config   licenses
$ ls 
.. kafka-console-consumer.sh


$ ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-topic --from-beginning





~





ðŸš€ Consuming messages from Kafka Topic from the beginning
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
ðŸ§  --from-beginning

Before trying to create a Kafka Topic ensure Kafka Server is up and running
[terminal]
$ ./bin/kafka-server-start.sh config/kraft/server-1.properties
$ ./bin/kafka-server-start.sh config/kraft/server-2.properties
$ ./bin/kafka-server-start.sh config/kraft/server-3.properties
...
[terminal]
$ ./bin/kafka-console-producer.sh --bootstrap-server localhost:9092,localhost:9094 --topic my-topic
> Message1
> Message2
> 

$ ./bin/kafka-console-consumer.sh  --bootstrap-server localhost:9092,localhost:9094 --topic my-topic ðŸ’¥--from-beginning
Message1
Message2
|
=======================================================================================================================================

[terminal]
$ cd {WORKSPACE}
$ cd kafka
$ ls
LICENSE  ðŸ’¥bin      libs    site-docs
NOTICE   config   licenses
$ ls 
.. kafka-console-consumer.sh

$ .kafka/bin/kafka-console-consumer.sh  --bootstrap-server localhost:9092,localhost:9094 --topic my-topic ðŸ’¥--from-beginning
Message1
Message2
|

ðŸ§ðŸ•µï¸ðŸ”Ž Notice that the kafka-console-consumer.sh script after reading the messages don't exit
 -> It's still running and waiting for more messages to run
 => As soon as new messages arrive to this Topic, it will read them right away

ðŸ§¨âš ï¸ðŸ¤¯ Notice that when a Consumer reads a message it won't be deleted from the Topic

ðŸ§ðŸ•µï¸ðŸ”Ž As soon as a new message is pushed to the Topic 
 -> All consumers subscribed to that Topic will get that message

...

ðŸ§ðŸ•µï¸ðŸ”Ž Consumers in this example are running in Terminal Windows
 -> However Consumers can be external applications like Spring Boot APIs, etc...





~





ðŸš€ Consuming new Kafka Messages only
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
=======================================================================================================================================
In order to avoid reading all messages, and only read the new ones
âŒ Remove the flag --from-beginning





~





ðŸš€ Consuming Key:Value pair messages from Kafka Topic
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
ðŸ§  --property "print.key=true" --property "print.value=true"
=======================================================================================================================================
When dealing with key:value pair messages..
ðŸ§ðŸ•µï¸ðŸ”Ž There is nothing you need to do on the Consumer side, is the Producer responsible on sending the messages in that format
For that we need to add to producer properties "parse.key=true" & "key.separator=:"

$ ./bin/kafka-console-producer.sh --bootstrap-server localhost:9092,localhost:9094 --topic ðŸ’¥my-topic
--property "parse.key=true" --property "key.separator=:"
> key1 Message3

ðŸ§¨âš ï¸ðŸ¤¯ By default Consumers will only display the Value part.
This is because the properties defined to print the key part and the value part aswell, are defined as follows:
print.key=false
print.value=true


$ .kafka/bin/kafka-console-consumer.sh  --bootstrap-server localhost:9092,localhost:9094 --topic my-topic 
--property "print.key=true"ðŸ’¥ --property "print.value=true"ðŸ’¥  --from-beginning
null Message1
null Message2
key1 Message3
|

ðŸ§¨âš ï¸ðŸ¤¯ Notice we can hide values and print key data only
$ .kafka/bin/kafka-console-consumer.sh  --bootstrap-server localhost:9092,localhost:9094 --topic my-topic 
--property "print.key=true" --property "print.value=false"ðŸ’¥  --from-beginning
null
null
Message3
|





~





ðŸš€ Consumming Kafka Messages in Order
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
=======================================================================================================================================
ðŸ§ðŸ•µï¸ðŸ”Ž  Kafka Topic is split into multiple partitions.
To determine which partition to choose to store a message, Kafka will use a hash of a message key.
If there is no key, then Kafka will equally distribute messages across multiple partitions using round robin algorithm.


ðŸ§¨âš ï¸ðŸ¤¯ If you want to read messages in the order they were stored, these messages need to use exactly the same key.
If messages have the same key, they will be stored in the same partition and they will be read in the same order.


[terminal(1)]
$ cd {WORKSPACE}
$ cd kafka
$ ls
LICENSE  ðŸ’¥bin      libs    site-docs
NOTICE   config   licenses
$ ls 
..  kafka-console-producer.sh  kafka-console-consumer.sh

$ ./kafka/bin/kafka-console-producer.sh --create --bootstrap-server localhost:9092 --topic ordered-messages --partitions 3 --replication-factor 3
Created topic ordered-messages

$ ./kafka/bin/kafka-console-producer.sh  --boostrap-server localhost:9092 --topic ordered-messages 
--property "parse.key=true" --property "key.separator=:"
> 1:First
> 1:Second
> 1:Third
> 1:Fourth
> 1:Fifth
> 1:Sixth
> a:a
> b:b
> c:c
> d:d
> e:e
> f:f
> g:g

[terminal(2)]
$ ./kafka/bin/kafka-console-consumer.sh --boostrap-server localhost:9092 --topic ordered-messages 
--from-beginningðŸ’¥ --property "print.key=tue"ðŸ’¥
1    First
2    Second
3    Third
4    Fourth
5    Fifth
6    Sixth
f    f
g    g
a    a
c    c
b    b
d    d
e    e


Now notice that a list of messages with the same key. They are all ordered.
And those messages that were stored with a different key.
Even though we send them in order, their order is different when we read them.