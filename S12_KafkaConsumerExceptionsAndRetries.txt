üì¢ Apache Kafka for Event-Driven Spring Boot Microservices  by Sergety Kargopolov
=======================================================================================================================================

üìù S01 : Apache Kafka Introduction 
üìù S02 : Apache Kafka Broker
üìù S03 : Kafka Topics - CLI
üìù S04 : Kafka Producers - CLI
üìù S05 : Kafka Consumers - CLI
üìù S06 : Kafka Producer - Spring Boot Microservice
üìù S07 : Kafka Producer - Acknowledgment & Retries
üìù S08 : Kafka Producer - Idempotency
üìù S09 : Kafka Consumer - Spring Boot Microservice
üìù S10 : Kafka Consumer - Handling Deserialization Errors
üìù S11 : Kafka Consumer - Kafka Consumer Dead Letter Topic
üìù S12 : Kafka Consumer - Exceptions and Retries
üìù S13 : Kafka Consumer - Multiple Consumers in a Consumer Group
üìù S14 : Kafka Consumer Idempotency
üìù S15 : Apache Kafka Transactions
üìù S16 : Apache Kafka and Database Transactions
üìù S17 : Integration Testing - Kafka Producer
üìù S18 : Integration Testing - Kafka Consumer
üìù S19 : Saga Design Pattern I  - with Apache Kafka
üìù S20 : Saga Design Pattern II - Compensating Transactions
üìù S21 : Appendix A: Run Apache Kafka in a Docker Container
üìù S22 : Appendix B: Install Apache Kafka on Windows





üì£ Section 12 - Kafka Consumer - Exceptions and Retries
=======================================================================================================================================
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>


üöÄ Kafka Consumer : Exception Handling and Retries  - Introduction
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
=======================================================================================================================================

So far, we've seen than if Kafka Consumer is not able to deserialize a Message
 -> By default because of the retry mechanism it will try to process that message again and again
 -> To avoid that we could use an ErrorDeserializerHandler which by default will just ignore it
... That could be our first attempt to try to solve it, however the message will be just ignored it.
A better approach will be to send it to a DLT

üìù What happens if the error we're dealing with occurs after the message was deserialized‚ùì
(This is the message was received by the Consumer but when processing it we got an issue)
---------------
 o If Exception is Retryable, then:
   -> Configure a waiting time
   -> Define the Number of retries
   
   => After number of retries get exhausted send it to DLT





~





üöÄ Creating Retryable and Non-Retryable Exceptions in Kafka
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
=======================================================================================================================================


üìù com.learning.kafka.emailnotification.error.RetryableException

[‚úèÔ∏è#~/...RetryableException]
public class RetryableException extends RuntimeException {
    
    public Retryable(String message) {
        super(message);
    }

    public Retryable(Throwable throwable) {
        super(throwable);
    }
}


üìù com.learning.kafka.emailnotification.error.NonRetryableException

[‚úèÔ∏è#~/...NonRetryableException]
public class NonRetryableException extends RuntimeException {
    
    public NonRetryableException(String message) {
        super(message);
    }

    public NonRetryableException(Throwable throwable) {
        super(throwable);
    }
}


‚úèÔ∏è>>> In the following lessons we'll register this classes within our ErrorHandler





~





üöÄ Configure DefaultErrorHandler with a list of not Retryable Exceptions
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
üß®‚ö†Ô∏èü§Ø DefaultErrorHandler provides default implementation to handle exceptions that can take place during message exceptions.
 -> We can configure this error object with a list of exceptions that are Not Retrievable.
    Then if a Not Retrievable exception is thrown, this error handler will not attempt to retry consuming that message again
    and instead it will send this message to a Dead Letter Topic (DLT)
    Execution will continue and the next message in line will be consumed

üßêüïµÔ∏èüîé >>>
 => This can be achieved by passing that list to the .addNotRetriableExceptions(Class<? extends Exception>... exceptionTypes);
 => .addNotRetriableExceptions(...) Allow us to register more than one exception if needed separated by comma
    ‚úèÔ∏è>>> errorHandler.addNotRetriableExceptions(NotRetryableException.class, HttpServerErrorException.class);
 => Alternatively we can catch the different exceptions in our Kafka Listener and then throw the custom NotRetryableException


‚ùì‚ùì‚ùì Difference between CommonErrorHandler vs DefaultErrorHandler
---------------
CommonErrorHandler is an Interface that generalizes error handling
DefaultErrorHandler is a concrete implementation of CommonErrorHandler
.....
In Spring Kafka < 2.8, you had ErrorHandler and BatchErrorHandler.
In 2.8+, these were unified under CommonErrorHandler.
DefaultErrorHandler implements CommonErrorHandler, so it's forward-compatible.

When to use what?
Use DefaultErrorHandler if u want default retry + DLQ
.....
Implement CommonErrorHandler yourself if you want full control (Custom Logic)	
e.g. Send exhausted messages to a DLQ
     If u have batch listeners, use a CommonErrorHandler with batch support
=======================================================================================================================================

Let's register NonRetryableException with ErrorHandler object...

At this moment we've defined a KafkaConfiguration class annotated with @Configuration
 -> It defines ConsumerFactory and ConcurrentKafkaListenerContainerFactory @Bean's
.....
üìù ConsumerFactory >>>
The ConsumerFactory defines a Consumer Properties Map called config which is passed as argument to the DefaultKafkaConsumerFactory
 -> Properties like GROUP_ID_CONFIG | BOOTSTRAP_SERVERS_CONFIG | KEY_DESERIALIZER_CLASS_CONFIG | VALUE_DESERIALIZER_CLASS_CONFIG | TRUSTED_PACKAGES

üìù ConcurrentKafkaListenerContainerFactory >>>
Once instantiated this ListenerFactory via ConcurrentKafkaListenerContainerFactory
 -> We'll set the ConsumerFactory and ErrorHandler
   - The ConsumerFactory is the @Bean created at the previous method
   - The ErrorHandler is created via DefaultErrorHandler which takes a DeadLetterPublishingRecoverer object as constructor argument
   - The DeadLetterPublishingRecoverer takes a KafkaTemplate object as constructor argument
...
KafkaTemplate is a @Bean method that takes a ProducerFactory as argument
This ProducerFactory defines a Producer Properties Map called config
 -> Properties like BOOTSTRAP_SERVERS_CONFIG | KEY_SERIALIZER_CLASS_CONFIG | VALUE_SERIALIZER_CLASS_CONFIG
.....

üß®‚ö†Ô∏èü§Ø DefaultErrorHandler provides default implementation to handle exceptions that can take place during message exceptions.
 -> We can configure this error object with a list of exceptions that are not retrievable.
    Then if a not retrievable exception is thrown, this error handler will not attempt to retry consuming message again
    and instead it will send this message to a Dead Letter Topic (DLT)
    Execution will continue and the next message in line will be consumed
 => This can be achieved by passing that list to the .addNotRetriableExceptions(Class<? extends Exception>... exceptionTypes);
 => .addNotRetriableExceptions(...) Allow us to register more than one exception if needed separated by comma
    ‚úèÔ∏è>>> errorHandler.addNotRetriableExceptions(NotRetryableException.class, HttpServerErrorException.class);
 => Alternatively we can catch the different exceptions in our Kafka Listener and then throw the custom NotRetryableException   
...



<EmailNotificationMicroservice>
[‚úèÔ∏è#~/...KafkaConsumerConfiguration]
...
import org.springframework.kafka.listener.DefaultErrorHandler;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.support.serializer.ErrorHandlingDeserializer;
import ...

@Configuration
public class KafkaConsumerConfiguration {

    private Environment environment;

    public KafkaConsumerConfiguration(Environment environment) {
        this.environment = environment;
    }

    @Bean
    public ConsumerFactory<String, Object> consumerFactory() {
        Map<String, Object> config = new HashMap<>();
        config.put(ConsumerConfig.GROUP_ID_CONFIG, environment.getProperty("spring.kafka.consumer.group-id"));
        config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, environment.getProperty("spring.kafka.consumer.bootstrap-servers"));
        config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        //config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
        config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, üí•ErrorHandlingDeserializer.classüí•);
        config.put(üí•ErrorHandlingDeserializer.VALUE_DESERIALIZER_CLASS, JsonDeserializer.classüí•);
        config.put(JsonDeserializer.TRUSTED_PACKAGES, environment.getProperty("spring.kafka.consumer.properties.spring.json.trusted.packages"));
        return new DefaultKafkaConsumerFactory<>(config);
    }

    @Bean
    ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(
        ConsumerFactory<String, Object> ConsumerFactory, KafkaTemplate<String, Object> kafkaTemplate) {
       ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
       factory.setConsumerFactory(consumerFactory);

       DefaultErrorHandler errorHandler = new DefaultErrorHandler(new DeadLetterPublishingRecoverer(kafkaTemplate));
       üí•errorHandler.addNotRetriableExceptions(NotRetryableException.class);üí•
       factory.setCommonErrorHandler(errorHandler);

       return factory;
    }

}





~





üöÄ Kafka Consumer Exceptions : NonRetryableException [DEMO]
===========================================================================================================================

[IntelliJ]
<EmailNotificationMicroservice>
[‚úèÔ∏è#~/...ProductCreatedEventHandler]
package com.learning.kafka.emailnotification.handler;

import com.learning.kafka.emailnotification.error.NotRetryableException;

import org.springframework.stereotype.Component;
import org.springframework.kafka.annotation.KafkaListener;

@Component
@KafkaListener(topics = "product-created-event-topic")
public class ProductCreatedEventHandler {

    private final Logger LOGGER = LoggerFactory.getLogger(this.getClass());

    @KafkaHandler
    public void handle(ProductCreatedEvent productCreatedEvent) {
        throw new NotRetryableException("An Error took place. No need to consume this message again.");
        //LOGGER.info("Received a new Event: " + productCreatedEvent.getTitle());
    }

}
~
üßêüïµÔ∏èüîé Once ErrorHandler notice this Exception...
 -> Since it was registered as a NotRetryableException this message won't be retried


~


[IntelliJ]
EmailNotificationMicroservice
  > ‚ñ∂Ô∏è EmailNotificationMicroserviceApplication


‚úèÔ∏è>>> Send Kafka Message via POSTMAN >>>
-------------------------
[POSTMAN]
[POST] http://localhost:{PORT}/products
Params | Authorization | Headers | ‚úÖBody | Pre-request Script | Tests | Settings
none | form-data | x-www-form-urlencoded | ‚úÖraw | binary | GraphQL | üí•JSON
~
{
    "title": "iPhone11(2)",
    "price": 800,
    "quantity": 19
}
...
‚úÖBody | Cookies | Headers(5) | Test Results                 Status: 201 Created  Time: 236 ms   Size: 205 B
Pretty | Raw | Preview | Visualize | Text 
 {productId}


...


[IntelliJ]
EmailNotificationMicroservice
  > ‚ñ∂Ô∏è EmailNotificationMicroserviceApplication
~
-

...


[terminal]
$ ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic product-created-events-topic.DLT \ 
  --from-beginning --property print.key=true --property print.value=true





~





üöÄ Configure DefaultErrorHandler with a list of Retryable Exceptions
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
üß®‚ö†Ô∏èü§Ø DefaultErrorHandler provides default implementation to handle exceptions that can take place during message exceptions.
 -> We can configure this error object with a list of exceptions that are Retrievable.
    Then if a Retrievable exception is thrown, this error handler will attempt to retry consuming message again
    and instead it will send this message to a Dead Letter Topic (DLT)
    Execution will continue and the next message in line will be consumed

üßêüïµÔ∏èüîé >>>
We can also add a Wait Time Interval by adding a FixedBackOff object as parameter to our DefaultErrorHandler
    ‚úèÔ∏è>>> new FixedBackOff(numberOfMilis, maxNumberOfRetries);
    ‚úèÔ∏è>>> DefaultErrorHandler errorHandler = new DefaultErrorHandler(
        new DeadLetterPublishingRecoverer(kafkaTemplate),
      üí•new FixedBackOff(5000, 3)
      );

‚úÖ >>>
 => This can be achieved by passing that list to the .addRetriableExceptions(Class<? extends Exception>... exceptionTypes);
 => .addRetriableExceptions(...) Allow us to register more than one exception if needed separated by comma
    ‚úèÔ∏è>>> errorHandler.addRetriableExceptions(RetryableException.class, TimeOutException.class);
 => Alternatively we can catch the different exceptions in our Kafka Listener and then throw the custom RetryableException
=======================================================================================================================================


[‚úèÔ∏è#~/...KafkaConsumerConfiguration.java]
@Configuration
public class KafkaConsumerConfiguration {

    @Autowired
    Environment environment;

    @Bean
    ConsumerFactory<String, Object> consumerFactory() {
        Map<String, Object> config = new HashMap<>();
        config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,
                environment.getProperty("spring.kafka.consumer.bootstrap-servers"));
        config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        config.put(ConsumerConfig.VALUE_DESERIALIZER_CALSS_CONFIG, ErrorHandlingDeserializer.class);
        config.put(ErrorHandlingDeserializer.VALUE_DESERIALIZER_CLASS, JsonDeserializer.class);
        config.put(JsonDeserializer.TRUSTED_PACKAGES,
                environment.getProperty("spring.kafka.consumer.properties.spring.json.trusted.packages"));
        config.put(ConsumerConfig.GROUP_ID_CONFIG, environment.getProperty("spring.kafka.consumer.group-id"));

        return new DefaultKafkaConsumerFactory<>(config);
    }
    ...

    @Bean
    ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(
        ConsumerFactory<String, Object> consumerFactory, KafkaTemplate<String, Object> kafkaTemplate
    ) {
        DefaultErrorHandler errorHandler = new DefaultErrorHandler(
            new DeadLetterPublishingRecoverer(kafkaTemplate),
            new FixedBackOff(5000, 3)
        );
        errorHandler.addNotRetryableExceptions(NotRetryableException.class);
        errorHandler.addNotRetryableExceptions(RetryableException.class);

        ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory);
        factory.setCommonErrorHandler(errorHandler);

        return factory;
    }

    @Bean
    KafkaTemplate<String, Object> kafkaTemplate(ProducerFactory<String, Object> producerFactory) {
        return new KafkaTemplate<>(producerFactory);
    }

    @Bean
    ProducerFactory<String, Object> producerFactory() {
        Map<String, Object> config = new HashMap<>();
        config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, environment.getProperty("spring.kafka.consumer.bootstrap-servers"));
        config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);

        return new DefaultKafkaProducerFactory<>(config);
    }
}





~





üöÄ Throwing a RetryableException
==========================================================================================================================================     

[‚úèÔ∏è#~/...ProductCreatedEventHandler.java]
@Component
@KafkaListener(topics="product-created-events-topic")
public class ProductCreatedEventHandler {

    private final Logger LOGGER = LoggerFactory.getLogger(this.getClass());
    private RestTemplate restTemplate;

    public ProductCreatedEventHandler(RestTemplate restTemplate) {
        this.restTemplate = restTemplate;
    }

    @KafkaHandler
    public void handle(ProductCreatedEvent productCreatedEvent) {
        //if(true) throw new NotRetryableException("An error took place. No need to consume this message again");
        LOGGER.info("Received a new event: " + productCreatedEent.getTitle());

        String requestUrl = "http://localhost:8082";
        try {
            ResponseEntity<String> response = restTemplate.exchange(requestUrl, HttpMethod.GET, null, String.class);
            if(response.getStatusCode().value() == HttpStatus.OK.value()) {
                LOGGER.info("Received response from a remote service: " + response.getBody());
            }
        } catch(ResourceAccessException | HttpServerErrorException | ex) {
            LOGGER.error(ex.getMessage());
            throw new RetryableException(ex);
        }
    }
}





~





üöÄ Overview of Mock Respnose Microservice
==========================================================================================================================================

<MockResponseMicroservice>
[‚úèÔ∏è#/...application.properties]
server.port=8082

<MockServiceMicroservice>
[‚úèÔ∏è#~/...StatusCheckController]
@RestController
@RequestMapping("/response")
public class StatusCheckController {

    @GetMapping("/200")
    ResponseEntity<String> response200String() {
        return ResponseEntity.ok().body("200");
    }

    @GetMapping("/500")
    ResponseEntity<String> response500String() {
        return ResponseEntity.internalServerError().build();
    }

}


[IntelliJ]
MockResponseMicroservice
  > ‚ñ∂Ô∏è MockServiceApplication


[POSTMAN]
[GET] http://localhost:8082/response/200    Status 200 ok
200
...
[GET] http://localhost:8082/response/500    Status 500 Internal Server Error





~





üöÄ Trying how retry works
==========================================================================================================================================

üìù Make our ProductCreatedEventHandler request point to  MockResponseMicroservice  /response/200 endpoint üëá...
---------------¬¥
<EmailNotifiactionMicroservice>
[‚úèÔ∏è#~/...ProductCreatedEventHandler.java]
@Component
@KafkaListener(topics="product-created-events-topic")
public class ProductCreatedEventHandler {

    private final Logger LOGGER = LoggerFactory.getLogger(this.getClass());
    
    private RestTemplate restTemplate;

    public ProductCreatedEventHandler(RestTemplate restTemplate) {
        this.restTemplate = restTemplate;
    }

    @KafkaHandler
    public void handle(ProductCreatedEvent productCreatedEvent) {
        //if(true) throw new NotRetryableException("An error took place. No need to consume this message again");
        LOGGER.info("Received a new event: " + productCreatedEent.getTitle());

        String requestUrl = "http://localhost:8082/response/200";  //üí• -> MockResponseMicroservice
        try {
            ResponseEntity<String> response = restTemplate.exchange(requestUrl, HttpMethod.GET, null, String.class);
            if(response.getStatusCode().value() == HttpStatus.OK.value()) {
                LOGGER.info("Received response from a remote service: " + response.getBody());
            }
        } catch(ResourceAccessException ex) {
            LOGGER.error(ex.getMessage());
            throw new RetryableException(ex);
        } catch(HttpServerErrorException | Exception ex) {
            LOGGER.error(ex.getMessage());
            throw new NotRetryableException(ex);
        }
    }
}


...

üìù Let's start all three microservices  üëá...
---------------
[IntelliJ]
ProductsMicroservice
  > ‚ñ∂Ô∏è ProductsApplication

[IntelliJ]
EmailNotificationMicroservice
  > ‚ñ∂Ô∏è EmailNotificationApplication

[IntelliJ]
MockResponseMicroservice
  > ‚ñ∂Ô∏è MockServiceApplication

..and KafkaConsumer CLI to read DLT messages:

[terminal]
% ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
--topic product-created-events-topic.DLT \
--property print.key=true \
--property print.value=true


~

‚úèÔ∏è>>> Let's make a Product Creation Request  üëá...
[POSTMAN]
[POST] http://localhost:{PORT}/products
{
    "title": "iPad Pro",
    "price": 1200,
    "quantity": 2
}

<ProductsMicroservice>
Once we request the Product Creation endpoint
 -> It will publish a  ¬¥ProductCreatedEvent¬¥ to  'product-created-events-topic'

<EmailNotifiactionMicroservice>
 -> Will read the ¬¥ProductCreatedEvent¬¥ message via  'ProductCreatedEventHandler'

...

‚õî Stop 'MockResponseMicroservice'
 -> This will throw a 'ResourceAccessException'
 => So, our application will enter on retry mode

To confirm this, add a break-point at:
  <EmailNotifiactionMicroservice> ProductCreatedEventHandler  -> handle method()
  -> Exactly when it throws the new RetryableException(...);


üîé >>>
Once the retry gets exhausted then it will send the message to the DLT
 ->  This is defined at <EmailNotifiactionMicroservice>KafkaConsumerConfiguration.DefaultErrorHandler

[terminal]
% ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
--topic product-created-events-topic.DLT \
--property print.key=true \
--property print.value=true
. . .
WARN [Consumer clientId=console-consumer, groupId=console-consumer-76235]
Error while fetching metadata with correlation id 10 : {product-created-events-topic.DLT=UNKNOWN_TOPIC_OR_PARTITION}
(org.apache.kafka.clients.NetworkClient)
14d80a50-234c-4b6c-a718-c58a3fe542a8    {"productId":"14d80a50-234c-4b6c-a718-c58a3fe542a8", "title":"iPad Pro", "price":1200, "quantity":19}

...

‚úèÔ∏è>>>
Having the breakpoints in place, let's stop the MockResponseMicroservice and make a Create Product request
 -> Once the throw new RetryableException(...) gets triggerred
 -> Start the MockResponseMicroservice again
 -> Check the EmailNotifiactionMicroservice doesn't enter to the breakpoint again
 -> Review the DLT doesn't get the message 

‚úÖ This allow us to check our retry mechanism is in place and the DLT is working correctly